{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==2.2.2\n",
      "  Obtaining dependency information for torch==2.2.2 from https://files.pythonhosted.org/packages/5c/01/5ab75f138bf32d7a69df61e4997e24eccad87cc009f5fb7e2a31af8a4036/torch-2.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tensorboard in c:\\program files\\python311\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (2023.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\python311\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Using cached torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.87 requires datasets[vision]~=2.19.0, but you have datasets 2.18.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires pandas==2.2.2, but you have pandas 2.1.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires Pillow==10.3.0, but you have pillow 9.5.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires protobuf==4.23.4, but you have protobuf 3.20.3 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tiktoken==0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tqdm==4.66.2, but you have tqdm 4.66.1 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires transformers==4.40.1, but you have transformers 4.40.0 which is incompatible.\n",
      "torchvision 0.18.1 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
      "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.2.2 which is incompatible.\n",
      "torchaudio 2.3.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.2.2 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.40.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (4.40.0)\n",
      "Requirement already satisfied: datasets==2.18.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n",
      "Requirement already satisfied: accelerate==0.29.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.29.3)\n",
      "Requirement already satisfied: evaluate==0.4.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.4.1)\n",
      "Requirement already satisfied: bitsandbytes==0.43.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.43.1)\n",
      "Requirement already satisfied: huggingface_hub==0.22.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.22.2)\n",
      "Requirement already satisfied: trl==0.8.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.8.6)\n",
      "Requirement already satisfied: peft==0.10.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (3.9.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.29.3) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.29.3) (2.2.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub==0.22.2) (4.9.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from trl==0.8.6) (0.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (2022.12.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers==4.40.0) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\program files\\python311\\lib\\site-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (9.5.0)\n",
      "Requirement already satisfied: matplotlib==3.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy==1.24.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas==2.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (2.1.0)\n",
      "Requirement already satisfied: tqdm==4.66.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (4.66.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.3.10)\n",
      "Requirement already satisfied: langdetect in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (1.0.9)\n",
      "Requirement already satisfied: torchvision in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.18.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas==2.1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas==2.1.0) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm==4.66.1) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from langdetect) (1.16.0)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Obtaining dependency information for torch==2.3.1 from https://files.pythonhosted.org/packages/d3/1d/a257913c89572de61316461db91867f87519146e58132cdeace3d9ffbe1f/torch-2.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed torch-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.87 requires datasets[vision]~=2.19.0, but you have datasets 2.18.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires pandas==2.2.2, but you have pandas 2.1.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires Pillow==10.3.0, but you have pillow 9.5.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires protobuf==4.23.4, but you have protobuf 3.20.3 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tiktoken==0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tqdm==4.66.2, but you have tqdm 4.66.1 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires transformers==4.40.1, but you have transformers 4.40.0 which is incompatible.\n",
      "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n",
      "torchaudio 2.3.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.3.1 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch\n",
    "%pip install \"torch==2.2.2\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n",
    "\n",
    "# Install remaining libraries\n",
    "%pip install \"Pillow==9.5.0\" \"matplotlib==3.8.0\" \"numpy==1.24.3\" \"pandas==2.1.0\" \"tqdm==4.66.1\" \"pytesseract\" \"langdetect\" \"torchvision\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (9.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n",
      "--2024-07-19 13:10:32--  https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/pol.traineddata [following]\n",
      "--2024-07-19 13:10:33--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/pol.traineddata\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19344135 (18M) [application/octet-stream]\n",
      "Saving to: '/usr/share/tesseract-ocr/4.00/tessdata/pol.traineddata.3'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 2,04M 9s\n",
      "    50K .......... .......... .......... .......... ..........  0% 8,81M 6s\n",
      "   100K .......... .......... .......... .......... ..........  0% 2,95M 6s\n",
      "   150K .......... .......... .......... .......... ..........  1% 17,0M 5s\n",
      "   200K .......... .......... .......... .......... ..........  1% 4,12M 5s\n",
      "   250K .......... .......... .......... .......... ..........  1% 36,8M 4s\n",
      "   300K .......... .......... .......... .......... ..........  1% 24,9M 3s\n",
      "   350K .......... .......... .......... .......... ..........  2% 8,55M 3s\n",
      "   400K .......... .......... .......... .......... ..........  2%  258M 3s\n",
      "   450K .......... .......... .......... .......... ..........  2% 4,19M 3s\n",
      "   500K .......... .......... .......... .......... ..........  2%  184M 3s\n",
      "   550K .......... .......... .......... .......... ..........  3% 6,94M 3s\n",
      "   600K .......... .......... .......... .......... ..........  3%  446M 2s\n",
      "   650K .......... .......... .......... .......... ..........  3%  496M 2s\n",
      "   700K .......... .......... .......... .......... ..........  3%  460M 2s\n",
      "   750K .......... .......... .......... .......... ..........  4%  193M 2s\n",
      "   800K .......... .......... .......... .......... ..........  4% 7,98M 2s\n",
      "   850K .......... .......... .......... .......... ..........  4%  849M 2s\n",
      "   900K .......... .......... .......... .......... ..........  5% 92,0M 2s\n",
      "   950K .......... .......... .......... .......... ..........  5% 40,9M 2s\n",
      "  1000K .......... .......... .......... .......... ..........  5% 4,05M 2s\n",
      "  1050K .......... .......... .......... .......... ..........  5%  290M 2s\n",
      "  1100K .......... .......... .......... .......... ..........  6%  168M 2s\n",
      "  1150K .......... .......... .......... .......... ..........  6%  676M 2s\n",
      "  1200K .......... .......... .......... .......... ..........  6%  439M 2s\n",
      "  1250K .......... .......... .......... .......... ..........  6% 21,5M 2s\n",
      "  1300K .......... .......... .......... .......... ..........  7% 14,2M 2s\n",
      "  1350K .......... .......... .......... .......... ..........  7%  238M 1s\n",
      "  1400K .......... .......... .......... .......... ..........  7%  888M 1s\n",
      "  1450K .......... .......... .......... .......... ..........  7%  984M 1s\n",
      "  1500K .......... .......... .......... .......... ..........  8%  229M 1s\n",
      "  1550K .......... .......... .......... .......... ..........  8%  345M 1s\n",
      "  1600K .......... .......... .......... .......... ..........  8%  493M 1s\n",
      "  1650K .......... .......... .......... .......... ..........  8%  110M 1s\n",
      "  1700K .......... .......... .......... .......... ..........  9%  453M 1s\n",
      "  1750K .......... .......... .......... .......... ..........  9% 21,9M 1s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  698M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 10% 9,36M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 10%  125M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 10%  833M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 10%  421M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 11% 7,78M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 11%  650M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 11%  935M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 11% 44,0M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 12%  153M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 12% 11,5M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 12%  223M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  271M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 13%  218M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 13%  911M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 13%  617M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 14% 10,4M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 14%  156M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 14%  534M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 14%  357M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 15%  165M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 15%  512M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 15%  591M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 15%  101M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 16%  179M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 16%  247M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 16%  654M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 16% 36,7M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 17%  226M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 17%  359M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 17% 9,50M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 17%  228M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 18%  208M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 18%  279M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 18%  581M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 19%  521M 1s\n",
      "  3600K .......... .......... .......... .......... .......... 19%  171M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 19%  469M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 19%  821M 1s\n",
      "  3750K .......... .......... .......... .......... .......... 20% 8,15M 1s\n",
      "  3800K .......... .......... .......... .......... .......... 20%  295M 1s\n",
      "  3850K .......... .......... .......... .......... .......... 20%  758M 1s\n",
      "  3900K .......... .......... .......... .......... .......... 20%  559M 1s\n",
      "  3950K .......... .......... .......... .......... .......... 21%  525M 1s\n",
      "  4000K .......... .......... .......... .......... .......... 21%  872M 1s\n",
      "  4050K .......... .......... .......... .......... .......... 21%  447M 1s\n",
      "  4100K .......... .......... .......... .......... .......... 21%  846M 1s\n",
      "  4150K .......... .......... .......... .......... .......... 22%  220M 1s\n",
      "  4200K .......... .......... .......... .......... .......... 22% 39,9M 1s\n",
      "  4250K .......... .......... .......... .......... .......... 22%  328M 1s\n",
      "  4300K .......... .......... .......... .......... .......... 23%  249M 1s\n",
      "  4350K .......... .......... .......... .......... .......... 23% 9,50M 1s\n",
      "  4400K .......... .......... .......... .......... .......... 23%  520M 1s\n",
      "  4450K .......... .......... .......... .......... .......... 23%  602M 1s\n",
      "  4500K .......... .......... .......... .......... .......... 24%  351M 1s\n",
      "  4550K .......... .......... .......... .......... .......... 24%  672M 1s\n",
      "  4600K .......... .......... .......... .......... .......... 24%  398M 1s\n",
      "  4650K .......... .......... .......... .......... .......... 24%  718M 1s\n",
      "  4700K .......... .......... .......... .......... .......... 25%  299M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 25%  418M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 25%  337M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 25%  364M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 26% 19,6M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 26%  473M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 26%  585M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 26%  300M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 27% 31,4M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 27%  329M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 27%  443M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 28% 6,63M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 28%  268M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 28%  280M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 28%  336M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 29%  417M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 29%  473M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 29%  707M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 29%  445M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 30% 1,21M 1s\n",
      "  5700K .......... .......... .......... .......... .......... 30%  521M 1s\n",
      "  5750K .......... .......... .......... .......... .......... 30%  698M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 30%  304M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 31%  120M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 31%  288M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 31%  288M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 32% 2,37M 1s\n",
      "  6050K .......... .......... .......... .......... .......... 32%  162M 1s\n",
      "  6100K .......... .......... .......... .......... .......... 32%  371M 1s\n",
      "  6150K .......... .......... .......... .......... .......... 32% 7,40M 1s\n",
      "  6200K .......... .......... .......... .......... .......... 33%  100M 1s\n",
      "  6250K .......... .......... .......... .......... .......... 33%  648M 1s\n",
      "  6300K .......... .......... .......... .......... .......... 33%  284M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 33%  903M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 34%  225M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 34%  216M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 34%  330M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 34%  361M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 35% 2,67M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 35%  116M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 35%  253M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 35%  422M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 36%  213M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 36%  579M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 36% 19,5M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 37%  186M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 37%  346M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 37% 10,0M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 37%  247M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 38%  116M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 38% 4,51M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 38% 23,9M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 38%  369M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 39% 9,13M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 39%  166M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 39%  312M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 39%  474M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 40% 26,0M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 40% 78,7M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 40% 51,1M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 41% 88,0M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 41%  209M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 41%  446M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 41% 2,32M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 42%  134M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 42%  318M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 42%  232M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 42%  436M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 43%  231M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 43%  292M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 43%  679M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 43% 19,0M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 44% 91,9M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 44%  555M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 44% 18,4M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 44% 1,86M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 45%  119M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 45%  227M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 45%  253M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 46%  248M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 46%  310M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 46%  605M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 46% 1,09G 0s\n",
      "  8850K .......... .......... .......... .......... .......... 47%  177M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 47%  537M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 47%  282M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 47%  372M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 48%  174M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 48% 2,27M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 48%  114M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 48%  192M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 49%  203M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 49% 10,2M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 49%  639M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 50% 1,01G 0s\n",
      "  9450K .......... .......... .......... .......... .......... 50%  152M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 50%  329M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 50%  196M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 51%  207M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 51%  215M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 51% 35,4M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 51% 12,7M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 52% 28,7M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 52% 9,34M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 52%  358M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 52% 29,8M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 53% 11,5M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 53% 36,0M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 53% 19,1M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 53% 7,85M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 54%  116M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 54%  341M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 54%  779M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 55% 36,4M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 55% 13,8M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 55% 21,6M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 55% 8,48M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 56%  140M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 56%  294M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 56%  348M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 56% 46,6M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 57% 7,09M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 57%  289M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 57% 4,46M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 57%  619M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 58%  213M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 58%  172M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 58%  255M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 59%  272M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 59%  124M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 59%  165M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 59% 21,6M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 60%  228M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 60%  504M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 60% 8,62M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 60% 4,18M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 61%  119M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 61% 37,1M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 61%  265M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 61%  332M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 62% 5,69M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 62%  312M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 62%  223M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 62%  299M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 63%  272M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 63%  380M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 63% 19,2M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 64%  117M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 64%  301M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 64% 4,55M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 64%  359M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 65%  147M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 65%  312M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 65% 7,21M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 65%  166M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 66% 6,70M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 66%  388M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 66%  893M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 66%  579M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 67%  210M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 67%  320M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 67% 51,8M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 68% 22,2M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 68% 15,9M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 68% 61,7M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 68% 15,6M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 69%  194M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 69% 11,6M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 69%  270M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 69% 12,4M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 70% 22,7M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 70% 94,7M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 70% 26,6M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 70% 99,8M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 71% 9,30M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 71%  347M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 71%  585M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 71%  254M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 72% 8,41M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 72%  198M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 72%  759M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 73%  164M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 73% 12,7M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 73%  416M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 73% 8,81M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 74%  136M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 74%  420M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 74%  218M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 74% 9,09M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 75%  205M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 75% 16,9M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 75%  302M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 75%  348M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 76% 7,09M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 76%  409M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 76%  680M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 77%  402M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 77%  192M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 77%  449M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 77% 9,55M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 78%  209M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 78%  230M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 78% 45,0M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 78% 5,99M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 79%  321M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 79% 69,5M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 79%  427M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 79% 9,68M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 80%  185M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 80% 17,7M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 80%  648M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 80%  757M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 81% 13,4M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 81%  137M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 81%  276M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 82% 46,0M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 82%  324M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 82% 71,9M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 82% 7,28M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 83%  136M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 83% 15,0M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 83%  345M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 83% 23,8M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 84%  138M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 84% 8,85M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 84%  555M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 84%  434M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 85% 69,6M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 85%  219M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 85% 16,5M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 86%  324M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 86% 18,6M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 86% 15,1M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 86%  225M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 87%  287M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 87% 6,12M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 87%  254M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 87%  338M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 88%  164M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 88% 6,72M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 88%  195M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 88%  350M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 89%  213M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 89%  247M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 89%  222M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 89%  367M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 90%  180M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 90% 85,8M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 90% 10,1M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 91%  305M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 91%  189M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 91% 5,20M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 91%  269M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 92%  129M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 92%  213M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 92% 11,4M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 92%  723M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 93% 28,9M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 93%  577M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 93% 62,1M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 93% 10,5M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 94%  169M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 94% 98,5M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 94%  327M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 95% 14,7M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 95% 93,8M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 95% 24,4M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 95% 4,02M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 96%  193M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 96%  369M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 96%  679M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 96%  679M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 97%  181M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 97%  265M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 97%  396M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 97%  417M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 98%  194M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 98% 84,9M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 98% 18,5M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 98%  388M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 99% 16,8M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 99%  397M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 99% 41,1M 0s\n",
      " 18850K .......... .......... .......... ..........           100%  272M=0,7s\n",
      "\n",
      "2024-07-19 13:10:36 (26,1 MB/s) - '/usr/share/tesseract-ocr/4.00/tessdata/pol.traineddata.3' saved [19344135/19344135]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesseract v5.3.3.20231005\n",
      " leptonica-1.83.1\n",
      "  libgif 5.2.1 : libjpeg 8d (libjpeg-turbo 2.1.4) : libpng 1.6.40 : libtiff 4.6.0 : zlib 1.2.13 : libwebp 1.3.2 : libopenjp2 2.5.0\n",
      " Found AVX2\n",
      " Found AVX\n",
      " Found FMA\n",
      " Found SSE4.1\n",
      " Found libarchive 3.7.2 zlib/1.3 liblzma/5.4.4 bz2lib/1.0.8 liblz4/1.9.4 libzstd/1.5.5\n",
      " Found libcurl/8.3.0 Schannel zlib/1.3 brotli/1.1.0 zstd/1.5.5 libidn2/2.3.4 libpsl/0.21.2 (+libidn2/2.3.3) libssh2/1.11.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tesseract OCR\n",
    "!apt-get update\n",
    "!apt-get install -y tesseract-ocr\n",
    "!apt-get install -y libtesseract-dev\n",
    "\n",
    "# Install pytesseract\n",
    "!pip install pytesseract\n",
    "!wget https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata -P /usr/share/tesseract-ocr/4.00/tessdata/\n",
    "\n",
    "# Verify the installation\n",
    "!tesseract --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from transformers import LlamaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import LlamaForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\olekm\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(\"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\") # I suggest to create ITSquad account. This token is private (Aleksander Majkowski)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80290599195a4131a188ebc3f22d1577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\"\n",
    "\n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    torch_dtype=torch.float32,  # Using float32 as dynamic quantization requires float32\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "# Quantize the model using PyTorch's dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    base_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "quantized_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(quantized_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model\n",
    "text = \"Some text to classify\"\n",
    "predicted_class = predict_sentiment(text)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6edb59c9f8a4efbb61ff8a7bd6efcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\"\n",
    "\n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,  # Use float16 if CUDA is available\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(base_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model\n",
    "#text = \"ble ble ble ble ble ble ble, Kaz Bałagane \"\n",
    "#predicted_class = predict_sentiment(text)\n",
    "#print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 3\n"
     ]
    }
   ],
   "source": [
    "#Ten kod służy tylko i wyłącznie do testów\n",
    "text = \"Tekst do klasyfikacji. Ala ma kota, kot ma Ale, ale Ala nie żyje\"\n",
    "predicted_class = predict_sentiment(text)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper code with low RAM USAGE, runs only on Linux venv\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "# Quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\" \n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model with quantization\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(base_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model //WORKs ONLY WITH POLSIH LANGUAGE\n",
    "#text = \"Gdzie w nocy tupta jeż?\"\n",
    "#predicted_class = predict_sentiment(text)\n",
    "#print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r\"/path\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_function(images_dir):\n",
    "\n",
    "    if os.path.exists(images_dir):\n",
    "        image_paths = [os.path.join(images_dir, filename) for filename in os.listdir(images_dir)]\n",
    "    else:\n",
    "        print(\"Provided path is incorrect\")\n",
    "        image_paths = []\n",
    "\n",
    "    document_labels = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = Image.open(os.path.join(images_dir, path))\n",
    "        try:\n",
    "            inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "            label_mapping = {0: 'id', 1: 'idObcy', 2: 'inne', 3: 'paszport', 4: 'paszportObcy', 5: 'prawoJazdy', 6: 'prawoJazdyObce'}\n",
    "            predicted_class_name = label_mapping[predicted_label]\n",
    "\n",
    "            document_labels.append({predicted_class_name: path})\n",
    "        \n",
    "        except Exception as e:  \n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "    \n",
    "    return document_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_ocr import extract_text_from_images\n",
    "\n",
    "def nlp_model_function(images_dir):\n",
    "    document_labels = cnn_model_function(images_dir)\n",
    "    print(document_labels)\n",
    "    \n",
    "    values_for_unknown_label = [entry for entry in document_labels if 'inne' in entry]\n",
    "    print(values_for_unknown_label)\n",
    "\n",
    "    nlp_dictionary = []\n",
    "\n",
    "    if len(values_for_unknown_label) > 0:\n",
    "        for entry in values_for_unknown_label:\n",
    "            path = list(entry.values())[0] #filrs element of every entry which is a one key:value pair dictionary\n",
    "            print(path)\n",
    "            text_from_image = extract_text_from_images([path])\n",
    "            print(text_from_image)\n",
    "            predicted_class = predict_sentiment(text_from_image)\n",
    "            print(predicted_class)\n",
    "            nlp_dictionary.append({\n",
    "                predicted_class:path\n",
    "            })\n",
    "    \n",
    "        document_labels.append(nlp_dictionary)\n",
    "        return document_labels\n",
    "\n",
    "    else:\n",
    "        return document_labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function():\n",
    "    dane = nlp_model_function(images_dir=\"/content/zdjecia\")\n",
    "    print(dane)\n",
    "    return dane\n",
    "\n",
    "main_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
