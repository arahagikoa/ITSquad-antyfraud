{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==2.2.2\n",
      "  Obtaining dependency information for torch==2.2.2 from https://files.pythonhosted.org/packages/5c/01/5ab75f138bf32d7a69df61e4997e24eccad87cc009f5fb7e2a31af8a4036/torch-2.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tensorboard in c:\\program files\\python311\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (2023.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\python311\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Using cached torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.87 requires datasets[vision]~=2.19.0, but you have datasets 2.18.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires pandas==2.2.2, but you have pandas 2.1.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires Pillow==10.3.0, but you have pillow 9.5.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires protobuf==4.23.4, but you have protobuf 3.20.3 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tiktoken==0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tqdm==4.66.2, but you have tqdm 4.66.1 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires transformers==4.40.1, but you have transformers 4.40.0 which is incompatible.\n",
      "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.2.2 which is incompatible.\n",
      "torchaudio 2.3.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.2.2 which is incompatible.\n",
      "torchvision 0.18.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.2.2 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.40.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (4.40.0)\n",
      "Requirement already satisfied: datasets==2.18.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n",
      "Requirement already satisfied: accelerate==0.29.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.29.3)\n",
      "Requirement already satisfied: evaluate==0.4.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.4.1)\n",
      "Collecting bitsandbytes==0.43.1\n",
      "  Obtaining dependency information for bitsandbytes==0.43.1 from https://files.pythonhosted.org/packages/32/e8/ab6c97347c99cf5d18d0750c7336270719b17cb0610eb0a44cf833aa378f/bitsandbytes-0.43.1-py3-none-win_amd64.whl.metadata\n",
      "  Using cached bitsandbytes-0.43.1-py3-none-win_amd64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: huggingface_hub==0.22.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.22.2)\n",
      "Requirement already satisfied: trl==0.8.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.8.6)\n",
      "Requirement already satisfied: peft==0.10.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (3.9.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.29.3) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.29.3) (2.2.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub==0.22.2) (4.9.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from trl==0.8.6) (0.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (2022.12.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers==4.40.0) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\program files\\python311\\lib\\site-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Using cached bitsandbytes-0.43.1-py3-none-win_amd64.whl (101.6 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (9.5.0)\n",
      "Requirement already satisfied: matplotlib==3.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy==1.24.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas==2.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (2.1.0)\n",
      "Requirement already satisfied: tqdm==4.66.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (4.66.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.3.10)\n",
      "Requirement already satisfied: langdetect in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (1.0.9)\n",
      "Requirement already satisfied: torchvision in c:\\program files\\python311\\lib\\site-packages (0.18.1+cu121)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas==2.1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas==2.1.0) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm==4.66.1) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from langdetect) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/e4/c3/a21a75dd2de8114a6876f16a36b033e3e62f8ade68085a711b24f4b57c17/torchvision-0.18.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.18.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Obtaining dependency information for torch==2.3.1 from https://files.pythonhosted.org/packages/d3/1d/a257913c89572de61316461db91867f87519146e58132cdeace3d9ffbe1f/torch-2.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Using cached torchvision-0.18.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed torch-2.3.1 torchvision-0.18.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.87 requires datasets[vision]~=2.19.0, but you have datasets 2.18.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires pandas==2.2.2, but you have pandas 2.1.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires Pillow==10.3.0, but you have pillow 9.5.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires protobuf==4.23.4, but you have protobuf 3.20.3 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tiktoken==0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tqdm==4.66.2, but you have tqdm 4.66.1 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires transformers==4.40.1, but you have transformers 4.40.0 which is incompatible.\n",
      "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n",
      "torchaudio 2.3.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.3.1 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch\n",
    "%pip install \"torch==2.2.2\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n",
    "\n",
    "# Install remaining libraries\n",
    "%pip install \"Pillow==9.5.0\" \"matplotlib==3.8.0\" \"numpy==1.24.3\" \"pandas==2.1.0\" \"tqdm==4.66.1\" \"pytesseract\" \"langdetect\" \"torchvision\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (9.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n",
      "--2024-07-08 20:45:39--  https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/pol.traineddata [following]\n",
      "--2024-07-08 20:45:39--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/pol.traineddata\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19344135 (18M) [application/octet-stream]\n",
      "Saving to: '/usr/share/tesseract-ocr/4.00/tessdata/pol.traineddata.1'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 2,30M 8s\n",
      "    50K .......... .......... .......... .......... ..........  0% 8,11M 5s\n",
      "   100K .......... .......... .......... .......... ..........  0% 3,10M 5s\n",
      "   150K .......... .......... .......... .......... ..........  1% 8,51M 5s\n",
      "   200K .......... .......... .......... .......... ..........  1% 3,28M 5s\n",
      "   250K .......... .......... .......... .......... ..........  1%  324M 4s\n",
      "   300K .......... .......... .......... .......... ..........  1% 44,2M 3s\n",
      "   350K .......... .......... .......... .......... ..........  2% 20,8M 3s\n",
      "   400K .......... .......... .......... .......... ..........  2% 22,6M 3s\n",
      "   450K .......... .......... .......... .......... ..........  2% 3,81M 3s\n",
      "   500K .......... .......... .......... .......... ..........  2% 23,6M 3s\n",
      "   550K .......... .......... .......... .......... ..........  3%  208M 3s\n",
      "   600K .......... .......... .......... .......... ..........  3% 46,8M 2s\n",
      "   650K .......... .......... .......... .......... ..........  3% 13,0M 2s\n",
      "   700K .......... .......... .......... .......... ..........  3%  434M 2s\n",
      "   750K .......... .......... .......... .......... ..........  4%  255M 2s\n",
      "   800K .......... .......... .......... .......... ..........  4% 68,5M 2s\n",
      "   850K .......... .......... .......... .......... ..........  4% 33,2M 2s\n",
      "   900K .......... .......... .......... .......... ..........  5% 4,08M 2s\n",
      "   950K .......... .......... .......... .......... ..........  5%  264M 2s\n",
      "  1000K .......... .......... .......... .......... ..........  5%  354M 2s\n",
      "  1050K .......... .......... .......... .......... ..........  5% 21,9M 2s\n",
      "  1100K .......... .......... .......... .......... ..........  6% 18,8M 2s\n",
      "  1150K .......... .......... .......... .......... ..........  6% 31,6M 2s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 16,3M 2s\n",
      "  1250K .......... .......... .......... .......... ..........  6%  329M 2s\n",
      "  1300K .......... .......... .......... .......... ..........  7% 27,4M 1s\n",
      "  1350K .......... .......... .......... .......... ..........  7% 57,1M 1s\n",
      "  1400K .......... .......... .......... .......... ..........  7%  920M 1s\n",
      "  1450K .......... .......... .......... .......... ..........  7% 22,1M 1s\n",
      "  1500K .......... .......... .......... .......... ..........  8%  241M 1s\n",
      "  1550K .......... .......... .......... .......... ..........  8% 15,1M 1s\n",
      "  1600K .......... .......... .......... .......... ..........  8%  323M 1s\n",
      "  1650K .......... .......... .......... .......... ..........  8% 66,6M 1s\n",
      "  1700K .......... .......... .......... .......... ..........  9%  121M 1s\n",
      "  1750K .......... .......... .......... .......... ..........  9% 18,7M 1s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  419M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 10%  568M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 10%  221M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 10% 12,5M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 10%  312M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 11%  301M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 11% 22,4M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 11% 32,2M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 11% 11,5M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 12%  231M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 12% 20,3M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 12% 78,6M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  708M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 13% 33,4M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 13% 39,5M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 13% 14,7M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 14%  526M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 14%  283M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 14% 4,63M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 14% 68,8M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 15%  187M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 15% 19,6M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 15%  682M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 15%  992M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 16%  212M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 16%  399M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 16%  807M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 16% 1,17G 1s\n",
      "  3200K .......... .......... .......... .......... .......... 17%  167M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 17%  632M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 17%  744M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 17%  848M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 18%  341M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 18%  459M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 18%  566M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 19%  678M 1s\n",
      "  3600K .......... .......... .......... .......... .......... 19% 30,8M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 19%  367M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 19%  667M 1s\n",
      "  3750K .......... .......... .......... .......... .......... 20% 6,22M 1s\n",
      "  3800K .......... .......... .......... .......... .......... 20%  202M 1s\n",
      "  3850K .......... .......... .......... .......... .......... 20%  663M 1s\n",
      "  3900K .......... .......... .......... .......... .......... 20%  217M 1s\n",
      "  3950K .......... .......... .......... .......... .......... 21%  201M 1s\n",
      "  4000K .......... .......... .......... .......... .......... 21%  320M 1s\n",
      "  4050K .......... .......... .......... .......... .......... 21%  192M 1s\n",
      "  4100K .......... .......... .......... .......... .......... 21%  409M 1s\n",
      "  4150K .......... .......... .......... .......... .......... 22%  206M 1s\n",
      "  4200K .......... .......... .......... .......... .......... 22%  426M 1s\n",
      "  4250K .......... .......... .......... .......... .......... 22%  313M 1s\n",
      "  4300K .......... .......... .......... .......... .......... 23%  673M 1s\n",
      "  4350K .......... .......... .......... .......... .......... 23% 1,95M 1s\n",
      "  4400K .......... .......... .......... .......... .......... 23%  224M 1s\n",
      "  4450K .......... .......... .......... .......... .......... 23%  568M 1s\n",
      "  4500K .......... .......... .......... .......... .......... 24%  316M 1s\n",
      "  4550K .......... .......... .......... .......... .......... 24%  513M 1s\n",
      "  4600K .......... .......... .......... .......... .......... 24%  547M 1s\n",
      "  4650K .......... .......... .......... .......... .......... 24%  771M 1s\n",
      "  4700K .......... .......... .......... .......... .......... 25%  415M 1s\n",
      "  4750K .......... .......... .......... .......... .......... 25%  429M 1s\n",
      "  4800K .......... .......... .......... .......... .......... 25%  407M 1s\n",
      "  4850K .......... .......... .......... .......... .......... 25%  273M 1s\n",
      "  4900K .......... .......... .......... .......... .......... 26%  301M 1s\n",
      "  4950K .......... .......... .......... .......... .......... 26%  655M 1s\n",
      "  5000K .......... .......... .......... .......... .......... 26%  911M 1s\n",
      "  5050K .......... .......... .......... .......... .......... 26%  696M 1s\n",
      "  5100K .......... .......... .......... .......... .......... 27%  155M 1s\n",
      "  5150K .......... .......... .......... .......... .......... 27%  316M 1s\n",
      "  5200K .......... .......... .......... .......... .......... 27%  468M 1s\n",
      "  5250K .......... .......... .......... .......... .......... 28%  214M 1s\n",
      "  5300K .......... .......... .......... .......... .......... 28%  287M 1s\n",
      "  5350K .......... .......... .......... .......... .......... 28%  275M 1s\n",
      "  5400K .......... .......... .......... .......... .......... 28%  291M 1s\n",
      "  5450K .......... .......... .......... .......... .......... 29%  408M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 29%  406M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 29%  994M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 29%  755M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 30%  320M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 30%  948M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 30%  347M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 30%  226M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 31%  315M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 31%  999M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 31% 1,01G 0s\n",
      "  6000K .......... .......... .......... .......... .......... 32%  969M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 32% 9,83M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 32%  132M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 32%  220M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 33% 1,10M 1s\n",
      "  6250K .......... .......... .......... .......... .......... 33%  564M 1s\n",
      "  6300K .......... .......... .......... .......... .......... 33% 1,05G 1s\n",
      "  6350K .......... .......... .......... .......... .......... 33% 1,21G 0s\n",
      "  6400K .......... .......... .......... .......... .......... 34%  260M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 34%  270M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 34% 1,19G 0s\n",
      "  6550K .......... .......... .......... .......... .......... 34% 1,06G 0s\n",
      "  6600K .......... .......... .......... .......... .......... 35%  183M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 35%  875M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 35% 1022M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 35%  748M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 36%  330M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 36%  626M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 36%  724M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 37%  288M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 37%  329M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 37% 1,20G 0s\n",
      "  7100K .......... .......... .......... .......... .......... 37% 1017M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 38%  185M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 38%  539M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 38%  592M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 38%  977M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 39%  429M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 39%  686M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 39%  791M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 39%  727M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 40%  720M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 40%  956M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 40%  712M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 41%  401M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 41%  420M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 41%  233M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 41%  525M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 42%  162M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 42%  347M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 42%  946M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 42%  730M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 43%  207M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 43%  163M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 43%  807M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 43%  242M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 44%  260M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 44%  568M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 44%  624M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 44%  579M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 45%  434M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 45%  904M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 45%  935M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 46%  443M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 46%  398M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 46%  711M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 46% 41,4M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 47% 4,55M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 47%  236M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 47%  147M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 47%  335M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 48%  166M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 48%  490M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 48%  362M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 48%  143M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 49%  136M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 49%  401M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 49% 1015M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 50%  693M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 50% 2,88M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 50%  221M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 50%  205M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 51%  324M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 51%  355M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 51%  548M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 51%  790M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 52%  232M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 52%  585M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 52%  261M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 52%  460M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 53%  234M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 53%  258M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 53%  328M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 53%  530M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 54% 7,30M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 54%  191M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 54%  272M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 55%  259M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 55%  138M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 55%  547M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 55% 1,17G 0s\n",
      " 10550K .......... .......... .......... .......... .......... 56%  234M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 56%  119M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 56%  911M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 56% 11,9M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 57% 7,40M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 57%  835M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 57%  433M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 57% 7,49M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 58%  125M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 58%  420M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 58%  303M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 59%  767M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 59%  197M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 59%  963M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 59%  125M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 60% 16,4M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 60%  317M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 60%  732M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 60%  490M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 61% 27,3M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 61%  479M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 61% 16,9M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 61%  249M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 62%  219M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 62%  252M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 62% 1,48M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 62%  289M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 63%  219M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 63%  243M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 63%  477M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 64% 90,8M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 64% 40,0M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 64%  424M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 64%  519M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 65% 51,0M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 65%  515M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 65%  563M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 65%  732M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 66% 6,08M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 66% 9,28M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 66%  387M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 66% 17,6M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 67%  190M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 67%  264M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 67%  878M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 68%  500M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 68%  158M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 68%  320M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 68%  553M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 69%  330M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 69% 45,0M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 69%  487M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 69%  762M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 70%  425M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 70%  260M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 70%  230M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 70%  364M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 71%  263M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 71%  516M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 71%  367M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 71%  274M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 72%  328M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 72%  567M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 72%  986M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 73%  378M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 73% 2,84M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 73%  312M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 73%  206M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 74%  282M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 74%  247M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 74%  319M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 74%  679M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 75%  437M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 75%  568M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 75%  618M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 75%  501M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 76%  337M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 76%  688M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 76% 3,90M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 77%  127M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 77%  334M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 77%  845M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 77%  672M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 78%  348M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 78% 11,5M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 78%  554M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 78%  351M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 79%  282M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 79%  670M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 79%  659M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 79%  990M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 80%  343M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 80%  531M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 80%  648M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 80%  564M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 81%  391M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 81%  374M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 81%  372M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 82%  176M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 82%  307M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 82%  568M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 82% 8,40M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 83% 97,5M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 83%  283M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 83% 65,1M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 83%  508M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 84%  210M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 84% 36,7M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 84%  688M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 84% 34,8M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 85%  102M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 85% 7,40M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 85% 53,9M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 86% 7,08M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 86%  185M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 86% 33,4M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 86% 56,5M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 87% 37,0M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 87% 8,59M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 87%  307M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 87%  628M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 88%  146M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 88%  286M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 88% 34,0M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 88% 16,7M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 89%  168M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 89% 6,08M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 89%  247M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 89%  226M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 90%  145M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 90%  336M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 90% 9,87M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 91% 60,2M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 91% 36,0M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 91% 59,4M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 91% 13,2M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 92%  189M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 92% 99,2M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 92% 9,37M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 92%  234M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 93% 10,7M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 93%  294M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 93%  387M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 93% 17,2M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 94%  204M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 94%  932M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 94% 13,9M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 95%  300M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 95% 27,8M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 95% 45,1M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 95%  121M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 96% 14,3M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 96% 9,49M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 96% 44,6M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 96%  270M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 97% 19,8M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 97%  178M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 97% 14,1M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 97% 31,3M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 98%  191M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 98%  145M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 98% 21,2M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 98%  219M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 99% 14,8M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 99%  330M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 99% 11,3M 0s\n",
      " 18850K .......... .......... .......... ..........           100%  130M=0,5s\n",
      "\n",
      "2024-07-08 20:45:41 (34,5 MB/s) - '/usr/share/tesseract-ocr/4.00/tessdata/pol.traineddata.1' saved [19344135/19344135]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesseract v5.3.3.20231005\n",
      " leptonica-1.83.1\n",
      "  libgif 5.2.1 : libjpeg 8d (libjpeg-turbo 2.1.4) : libpng 1.6.40 : libtiff 4.6.0 : zlib 1.2.13 : libwebp 1.3.2 : libopenjp2 2.5.0\n",
      " Found AVX2\n",
      " Found AVX\n",
      " Found FMA\n",
      " Found SSE4.1\n",
      " Found libarchive 3.7.2 zlib/1.3 liblzma/5.4.4 bz2lib/1.0.8 liblz4/1.9.4 libzstd/1.5.5\n",
      " Found libcurl/8.3.0 Schannel zlib/1.3 brotli/1.1.0 zstd/1.5.5 libidn2/2.3.4 libpsl/0.21.2 (+libidn2/2.3.3) libssh2/1.11.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tesseract OCR\n",
    "!apt-get update\n",
    "!apt-get install -y tesseract-ocr\n",
    "!apt-get install -y libtesseract-dev\n",
    "\n",
    "# Install pytesseract\n",
    "!pip install pytesseract\n",
    "!wget https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata -P /usr/share/tesseract-ocr/4.00/tessdata/\n",
    "\n",
    "# Verify the installation\n",
    "!tesseract --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from transformers import LlamaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import LlamaForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\olekm\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "login(\"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\") # I suggest to create ITSquad account. This token is private (Aleksander Majkowski)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80290599195a4131a188ebc3f22d1577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\"\n",
    "\n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    torch_dtype=torch.float32,  # Using float32 as dynamic quantization requires float32\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "# Quantize the model using PyTorch's dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    base_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "quantized_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(quantized_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model\n",
    "text = \"Some text to classify\"\n",
    "predicted_class = predict_sentiment(text)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\"\n",
    "\n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,  # Use float16 if CUDA is available\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(base_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model\n",
    "#text = \"ble ble ble ble ble ble ble, Kaz Baagane \"\n",
    "#predicted_class = predict_sentiment(text)\n",
    "#print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ten kod suy tylko i wycznie do testw\n",
    "text = \"Tekst do klasyfikacji. Ala ma kota, kot ma Ale, ale Ala nie yje\"\n",
    "predicted_class = predict_sentiment(text)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper code with low RAM USAGE, runs only on Linux venv\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "# Quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\" \n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model with quantization\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(base_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model //WORKs ONLY WITH POLSIH LANGUAGE\n",
    "#text = \"Gdzie w nocy tupta je?\"\n",
    "#predicted_class = predict_sentiment(text)\n",
    "#print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r\"/path\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_function(images_dir):\n",
    "\n",
    "    if os.path.exists(images_dir):\n",
    "        image_paths = [os.path.join(images_dir, filename) for filename in os.listdir(images_dir)]\n",
    "    else:\n",
    "        print(\"Provided path is incorrect\")\n",
    "        image_paths = []\n",
    "\n",
    "    document_labels = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = Image.open(os.path.join(images_dir, path))\n",
    "        try:\n",
    "            inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "            label_mapping = {0: 'id', 1: 'idObcy', 2: 'inne', 3: 'paszport', 4: 'paszportObcy', 5: 'prawoJazdy', 6: 'prawoJazdyObce'}\n",
    "            predicted_class_name = label_mapping[predicted_label]\n",
    "\n",
    "            document_labels.append({predicted_class_name: path})\n",
    "        \n",
    "        except Exception as e:  \n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "    \n",
    "    return document_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_ocr import extract_text_from_images\n",
    "\n",
    "def nlp_model_function(images_dir):\n",
    "    document_labels = cnn_model_function(images_dir)\n",
    "    print(document_labels)\n",
    "    \n",
    "    values_for_unknown_label = [entry for entry in document_labels if 'inne' in entry]\n",
    "    print(values_for_unknown_label)\n",
    "\n",
    "    nlp_dictionary = []\n",
    "\n",
    "    if len(values_for_unknown_label) > 0:\n",
    "        for entry in values_for_unknown_label:\n",
    "            path = list(entry.values())[0] #filrs element of every entry which is a one key:value pair dictionary\n",
    "            print(path)\n",
    "            text_from_image = extract_text_from_images([path])\n",
    "            print(text_from_image)\n",
    "            predicted_class = predict_sentiment(text_from_image)\n",
    "            print(predicted_class)\n",
    "            nlp_dictionary.append({\n",
    "                predicted_class:path\n",
    "            })\n",
    "    \n",
    "        document_labels.append(nlp_dictionary)\n",
    "        return document_labels\n",
    "\n",
    "    else:\n",
    "        return document_labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function():\n",
    "    dane = nlp_model_function(images_dir=\"/content/zdjecia\")\n",
    "    print(dane)\n",
    "    return dane\n",
    "\n",
    "main_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
