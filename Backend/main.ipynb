{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==2.2.2\n",
      "  Obtaining dependency information for torch==2.2.2 from https://files.pythonhosted.org/packages/5c/01/5ab75f138bf32d7a69df61e4997e24eccad87cc009f5fb7e2a31af8a4036/torch-2.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tensorboard in c:\\program files\\python311\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (2023.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\python311\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Using cached torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.87 requires datasets[vision]~=2.19.0, but you have datasets 2.18.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires pandas==2.2.2, but you have pandas 2.1.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires Pillow==10.3.0, but you have pillow 9.5.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires protobuf==4.23.4, but you have protobuf 3.20.3 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tiktoken==0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tqdm==4.66.2, but you have tqdm 4.66.1 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires transformers==4.40.1, but you have transformers 4.40.0 which is incompatible.\n",
      "torchvision 0.18.1 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
      "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.2.2 which is incompatible.\n",
      "torchaudio 2.3.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.2.2 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.40.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (4.40.0)\n",
      "Requirement already satisfied: datasets==2.18.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n",
      "Requirement already satisfied: accelerate==0.29.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.29.3)\n",
      "Requirement already satisfied: evaluate==0.4.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.4.1)\n",
      "Requirement already satisfied: bitsandbytes==0.43.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.43.1)\n",
      "Requirement already satisfied: huggingface_hub==0.22.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.22.2)\n",
      "Requirement already satisfied: trl==0.8.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.8.6)\n",
      "Requirement already satisfied: peft==0.10.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.40.0) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.18.0) (3.9.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.29.3) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate==0.29.3) (2.2.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub==0.22.2) (4.9.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from trl==0.8.6) (0.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.40.0) (2022.12.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers==4.40.0) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\program files\\python311\\lib\\site-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (9.5.0)\n",
      "Requirement already satisfied: matplotlib==3.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy==1.24.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas==2.1.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (2.1.0)\n",
      "Requirement already satisfied: tqdm==4.66.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (4.66.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.3.10)\n",
      "Requirement already satisfied: langdetect in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (1.0.9)\n",
      "Requirement already satisfied: torchvision in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.18.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib==3.8.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas==2.1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pandas==2.1.0) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm==4.66.1) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from langdetect) (1.16.0)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Obtaining dependency information for torch==2.3.1 from https://files.pythonhosted.org/packages/d3/1d/a257913c89572de61316461db91867f87519146e58132cdeace3d9ffbe1f/torch-2.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->torchvision) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed torch-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.87 requires datasets[vision]~=2.19.0, but you have datasets 2.18.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires pandas==2.2.2, but you have pandas 2.1.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires Pillow==10.3.0, but you have pillow 9.5.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires protobuf==4.23.4, but you have protobuf 3.20.3 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tiktoken==0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires tqdm==4.66.2, but you have tqdm 4.66.1 which is incompatible.\n",
      "autotrain-advanced 0.7.87 requires transformers==4.40.1, but you have transformers 4.40.0 which is incompatible.\n",
      "xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n",
      "torchaudio 2.3.1+cu121 requires torch==2.3.1+cu121, but you have torch 2.3.1 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch\n",
    "%pip install \"torch==2.2.2\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n",
    "\n",
    "# Install remaining libraries\n",
    "%pip install \"Pillow==9.5.0\" \"matplotlib==3.8.0\" \"numpy==1.24.3\" \"pandas==2.1.0\" \"tqdm==4.66.1\" \"pytesseract\" \"langdetect\" \"torchvision\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\olekm\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (9.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-07-10 18:39:13--  https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/pol.traineddata [following]\n",
      "--2024-07-10 18:39:13--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/pol.traineddata\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19344135 (18M) [application/octet-stream]\n",
      "Saving to: '/usr/share/tesseract-ocr/4.00/tessdata/pol.traineddata.2'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 9,19M 2s\n",
      "    50K .......... .......... .......... .......... ..........  0% 8,57M 2s\n",
      "   100K .......... .......... .......... .......... ..........  0% 3,64M 3s\n",
      "   150K .......... .......... .......... .......... ..........  1% 12,8M 3s\n",
      "   200K .......... .......... .......... .......... ..........  1% 3,81M 3s\n",
      "   250K .......... .......... .......... .......... ..........  1% 17,8M 3s\n",
      "   300K .......... .......... .......... .......... ..........  1% 17,4M 2s\n",
      "   350K .......... .......... .......... .......... ..........  2% 28,0M 2s\n",
      "   400K .......... .......... .......... .......... ..........  2% 24,3M 2s\n",
      "   450K .......... .......... .......... .......... ..........  2% 5,44M 2s\n",
      "   500K .......... .......... .......... .......... ..........  2% 19,4M 2s\n",
      "   550K .......... .......... .......... .......... ..........  3% 32,7M 2s\n",
      "   600K .......... .......... .......... .......... ..........  3% 42,6M 2s\n",
      "   650K .......... .......... .......... .......... ..........  3% 29,0M 2s\n",
      "   700K .......... .......... .......... .......... ..........  3% 39,8M 2s\n",
      "   750K .......... .......... .......... .......... ..........  4% 60,6M 2s\n",
      "   800K .......... .......... .......... .......... ..........  4% 26,0M 1s\n",
      "   850K .......... .......... .......... .......... ..........  4% 38,7M 1s\n",
      "   900K .......... .......... .......... .......... ..........  5% 44,7M 1s\n",
      "   950K .......... .......... .......... .......... ..........  5% 7,28M 1s\n",
      "  1000K .......... .......... .......... .......... ..........  5% 66,4M 1s\n",
      "  1050K .......... .......... .......... .......... ..........  5% 3,52M 2s\n",
      "  1100K .......... .......... .......... .......... ..........  6%  258M 1s\n",
      "  1150K .......... .......... .......... .......... ..........  6%  684M 1s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 1,11G 1s\n",
      "  1250K .......... .......... .......... .......... ..........  6%  513M 1s\n",
      "  1300K .......... .......... .......... .......... ..........  7%  267M 1s\n",
      "  1350K .......... .......... .......... .......... ..........  7%  790M 1s\n",
      "  1400K .......... .......... .......... .......... ..........  7%  494M 1s\n",
      "  1450K .......... .......... .......... .......... ..........  7% 1015M 1s\n",
      "  1500K .......... .......... .......... .......... ..........  8%  276M 1s\n",
      "  1550K .......... .......... .......... .......... ..........  8%  877M 1s\n",
      "  1600K .......... .......... .......... .......... ..........  8%  921M 1s\n",
      "  1650K .......... .......... .......... .......... ..........  8%  667M 1s\n",
      "  1700K .......... .......... .......... .......... ..........  9%  213M 1s\n",
      "  1750K .......... .......... .......... .......... ..........  9% 3,80M 1s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  557M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 10%  403M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 10%  814M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 10% 1007M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 10% 1,04G 1s\n",
      "  2050K .......... .......... .......... .......... .......... 11%  195M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 11%  941M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 11% 3,01M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 11%  515M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 12%  224M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 12%  157M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 12%  353M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  590M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 13%  421M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 13% 1,10G 1s\n",
      "  2550K .......... .......... .......... .......... .......... 13% 3,97M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 14%  567M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 14%  273M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 14%  357M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 14%  825M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 15%  549M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 15%  730M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 15% 1,01G 1s\n",
      "  2950K .......... .......... .......... .......... .......... 15% 1015M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 16%  432M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 16%  419M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 16%  684M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 16%  815M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 17%  448M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 17% 3,37M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 17%  349M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 17%  677M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 18% 1,62M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 18%  527M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 18%  932M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 19%  120M 1s\n",
      "  3600K .......... .......... .......... .......... .......... 19%  182M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 19%  475M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 19%  102M 1s\n",
      "  3750K .......... .......... .......... .......... .......... 20%  242M 1s\n",
      "  3800K .......... .......... .......... .......... .......... 20%  793M 1s\n",
      "  3850K .......... .......... .......... .......... .......... 20% 1,19G 1s\n",
      "  3900K .......... .......... .......... .......... .......... 20% 1,04G 1s\n",
      "  3950K .......... .......... .......... .......... .......... 21%  244M 1s\n",
      "  4000K .......... .......... .......... .......... .......... 21% 1,10G 1s\n",
      "  4050K .......... .......... .......... .......... .......... 21%  413M 1s\n",
      "  4100K .......... .......... .......... .......... .......... 21%  768M 1s\n",
      "  4150K .......... .......... .......... .......... .......... 22%  349M 1s\n",
      "  4200K .......... .......... .......... .......... .......... 22% 1,09G 1s\n",
      "  4250K .......... .......... .......... .......... .......... 22% 1,05G 1s\n",
      "  4300K .......... .......... .......... .......... .......... 23%  310M 1s\n",
      "  4350K .......... .......... .......... .......... .......... 23%  185M 1s\n",
      "  4400K .......... .......... .......... .......... .......... 23%  497M 1s\n",
      "  4450K .......... .......... .......... .......... .......... 23%  828M 1s\n",
      "  4500K .......... .......... .......... .......... .......... 24%  387M 1s\n",
      "  4550K .......... .......... .......... .......... .......... 24%  875M 1s\n",
      "  4600K .......... .......... .......... .......... .......... 24%  826M 1s\n",
      "  4650K .......... .......... .......... .......... .......... 24% 1,01G 1s\n",
      "  4700K .......... .......... .......... .......... .......... 25%  322M 1s\n",
      "  4750K .......... .......... .......... .......... .......... 25%  430M 1s\n",
      "  4800K .......... .......... .......... .......... .......... 25%  804M 1s\n",
      "  4850K .......... .......... .......... .......... .......... 25%  494M 1s\n",
      "  4900K .......... .......... .......... .......... .......... 26%  366M 1s\n",
      "  4950K .......... .......... .......... .......... .......... 26%  913M 1s\n",
      "  5000K .......... .......... .......... .......... .......... 26%  807M 1s\n",
      "  5050K .......... .......... .......... .......... .......... 26%  441M 1s\n",
      "  5100K .......... .......... .......... .......... .......... 27%  281M 1s\n",
      "  5150K .......... .......... .......... .......... .......... 27% 1,02G 0s\n",
      "  5200K .......... .......... .......... .......... .......... 27% 1,04G 0s\n",
      "  5250K .......... .......... .......... .......... .......... 28%  501M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 28%  767M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 28%  537M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 28%  763M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 29% 1,76M 1s\n",
      "  5500K .......... .......... .......... .......... .......... 29%  365M 1s\n",
      "  5550K .......... .......... .......... .......... .......... 29%  775M 1s\n",
      "  5600K .......... .......... .......... .......... .......... 29%  546M 1s\n",
      "  5650K .......... .......... .......... .......... .......... 30%  129M 1s\n",
      "  5700K .......... .......... .......... .......... .......... 30%  996M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 30%  454M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 30%  564M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 31%  301M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 31% 91,4M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 31% 27,1M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 32%  731M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 32% 29,7M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 32% 62,5M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 32%  706M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 33% 23,4M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 33%  713M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 33% 24,9M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 33%  786M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 34% 15,5M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 34%  423M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 34% 54,6M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 34% 57,5M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 35% 41,3M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 35% 27,6M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 35%  489M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 35% 7,38M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 36%  218M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 36%  557M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 36%  721M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 37%  358M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 37%  767M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 37%  939M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 37%  458M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 38%  198M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 38% 22,8M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 38%  339M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 38%  934M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 39% 52,1M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 39% 88,1M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 39% 52,7M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 39%  672M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 40% 32,1M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 40% 21,4M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 40% 29,2M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 41% 41,2M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 41% 53,0M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 41% 39,4M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 41% 32,1M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 42%  334M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 42% 46,5M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 42%  687M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 42% 33,7M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 43% 46,4M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 43% 40,4M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 43% 20,7M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 43%  700M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 44% 24,9M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 44%  114M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 44% 40,1M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 44% 41,8M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 45% 37,5M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 45% 46,3M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 45% 27,0M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 46%  417M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 46% 27,7M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 46% 75,0M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 46% 20,2M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 47% 1,06M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 47%  898M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 47%  630M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 47% 1019M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 48%  268M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 48%  903M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 48%  559M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 48%  475M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 49%  392M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 49%  224M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 49%  262M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 50% 1011M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 50%  191M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 50%  547M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 50% 1,07G 0s\n",
      "  9600K .......... .......... .......... .......... .......... 51%  748M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 51%  458M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 51%  167M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 51%  537M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 52%  534M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 52%  516M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 52%  743M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 52%  616M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 53%  718M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 53%  851M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 53% 1,17G 0s\n",
      " 10150K .......... .......... .......... .......... .......... 53%  630M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 54% 77,6M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 54%  925M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 54%  957M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 55% 1,01G 0s\n",
      " 10400K .......... .......... .......... .......... .......... 55%  421M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 55%  432M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 55%  952M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 56%  340M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 56%  568M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 56% 1,08G 0s\n",
      " 10700K .......... .......... .......... .......... .......... 56% 1,11G 0s\n",
      " 10750K .......... .......... .......... .......... .......... 57%  355M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 57%  422M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 57%  495M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 57%  762M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 58%  458M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 58%  716M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 58% 25,8M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 59%  785M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 59% 62,4M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 59%  551M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 59% 26,0M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 60% 32,9M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 60%  738M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 60% 31,0M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 60%  447M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 61% 34,2M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 61%  445M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 61% 8,19M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 61%  153M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 62%  405M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 62%  632M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 62%  959M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 62%  572M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 63%  475M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 63%  450M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 63%  566M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 64% 12,3M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 64% 35,3M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 64% 30,4M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 64%  376M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 65% 22,9M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 65%  645M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 65% 30,7M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 65% 71,6M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 66% 7,69M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 66%  582M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 66% 29,0M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 66%  732M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 67% 37,7M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 67% 36,7M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 67% 38,7M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 68%  314M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 68% 21,6M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 68%  845M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 68% 39,6M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 69% 40,1M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 69%  532M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 69% 43,8M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 69% 56,4M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 70% 35,0M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 70% 6,18M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 70%  425M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 70%  925M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 71%  408M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 71%  863M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 71%  934M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 71%  448M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 72%  376M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 72%  362M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 72%  950M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 73%  626M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 73% 3,25M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 73%  756M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 73%  155M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 74%  144M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 74%  406M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 74%  547M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 74%  927M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 75%  428M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 75% 1005M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 75% 1,01G 0s\n",
      " 14300K .......... .......... .......... .......... .......... 75%  401M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 76%  469M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 76%  441M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 76%  317M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 77%  398M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 77%  786M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 77% 1013M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 77% 3,79M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 78%  188M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 78%  225M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 78%  398M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 78%  130M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 79%  132M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 79%  786M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 79%  934M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 79%  928M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 80%  374M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 80% 2,84M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 80%  338M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 80%  435M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 81%  360M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 81%  463M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 81%  656M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 82%  408M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 82%  875M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 82%  608M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 82%  492M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 83%  311M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 83%  950M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 83% 1,06G 0s\n",
      " 15800K .......... .......... .......... .......... .......... 83%  213M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 84%  348M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 84%  243M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 84%  896M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 84%  431M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 85%  236M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 85% 42,9M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 85%  797M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 86%  930M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 86%  295M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 86%  484M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 86% 75,0M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 87%  500M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 87% 21,2M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 87%  904M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 87% 3,71M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 88%  308M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 88% 13,1M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 88%  320M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 88%  526M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 89% 60,0M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 89%  413M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 89%  952M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 89% 25,9M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 90%  373M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 90%  459M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 90% 34,8M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 91%  292M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 91%  540M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 91% 22,8M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 91% 77,4M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 92% 71,2M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 92%  194M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 92%  476M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 92% 21,3M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 93%  221M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 93% 41,7M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 93%  406M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 93%  178M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 94%  248M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 94% 27,5M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 94%  347M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 95% 25,4M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 95%  180M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 95%  903M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 95% 8,92M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 96%  352M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 96%  455M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 96%  253M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 96%  638M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 97%  199M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 97% 1,23M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 97% 2,75M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 97%  557M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 98% 2,68M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 98%  757M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 98%  429M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 98%  522M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 99% 2,61M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 99%  549M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 99%  855M 0s\n",
      " 18850K .......... .......... .......... ..........           100%  661M=0,6s\n",
      "\n",
      "2024-07-10 18:39:15 (31,9 MB/s) - '/usr/share/tesseract-ocr/4.00/tessdata/pol.traineddata.2' saved [19344135/19344135]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesseract v5.3.3.20231005\n",
      " leptonica-1.83.1\n",
      "  libgif 5.2.1 : libjpeg 8d (libjpeg-turbo 2.1.4) : libpng 1.6.40 : libtiff 4.6.0 : zlib 1.2.13 : libwebp 1.3.2 : libopenjp2 2.5.0\n",
      " Found AVX2\n",
      " Found AVX\n",
      " Found FMA\n",
      " Found SSE4.1\n",
      " Found libarchive 3.7.2 zlib/1.3 liblzma/5.4.4 bz2lib/1.0.8 liblz4/1.9.4 libzstd/1.5.5\n",
      " Found libcurl/8.3.0 Schannel zlib/1.3 brotli/1.1.0 zstd/1.5.5 libidn2/2.3.4 libpsl/0.21.2 (+libidn2/2.3.3) libssh2/1.11.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tesseract OCR\n",
    "!apt-get update\n",
    "!apt-get install -y tesseract-ocr\n",
    "!apt-get install -y libtesseract-dev\n",
    "\n",
    "# Install pytesseract\n",
    "!pip install pytesseract\n",
    "!wget https://github.com/tesseract-ocr/tessdata/raw/main/pol.traineddata -P /usr/share/tesseract-ocr/4.00/tessdata/\n",
    "\n",
    "# Verify the installation\n",
    "!tesseract --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from transformers import LlamaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import LlamaForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\olekm\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(\"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\") # I suggest to create ITSquad account. This token is private (Aleksander Majkowski)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80290599195a4131a188ebc3f22d1577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\"\n",
    "\n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    torch_dtype=torch.float32,  # Using float32 as dynamic quantization requires float32\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "# Quantize the model using PyTorch's dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    base_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "quantized_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(quantized_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model\n",
    "text = \"Some text to classify\"\n",
    "predicted_class = predict_sentiment(text)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6edb59c9f8a4efbb61ff8a7bd6efcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\"\n",
    "\n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,  # Use float16 if CUDA is available\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(base_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model\n",
    "#text = \"ble ble ble ble ble ble ble, Kaz Bałagane \"\n",
    "#predicted_class = predict_sentiment(text)\n",
    "#print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 3\n"
     ]
    }
   ],
   "source": [
    "#Ten kod służy tylko i wyłącznie do testów\n",
    "text = \"Tekst do klasyfikacji. Ala ma kota, kot ma Ale, ale Ala nie żyje\"\n",
    "predicted_class = predict_sentiment(text)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper code with low RAM USAGE, runs only on Linux venv\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "\n",
    "# Quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "local_path = r\"C:\\Users\\olekm\\OneDrive\\Pulpit\\ICFraud_github\\ITSquad-antyfraud\\NLP\\Training_model\\saved_model\" \n",
    "# Load the PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(local_path)\n",
    "\n",
    "# Load the base model with quantization\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the LoRA model\n",
    "nlp_model = PeftModel.from_pretrained(base_model, local_path)\n",
    "nlp_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Move inputs to the appropriate device\n",
    "    inputs = {k: v.to(nlp_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id\n",
    "\n",
    "# Test the model //WORKs ONLY WITH POLSIH LANGUAGE\n",
    "#text = \"Gdzie w nocy tupta jeż?\"\n",
    "#predicted_class = predict_sentiment(text)\n",
    "#print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r\"/path\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_function(images_dir):\n",
    "\n",
    "    if os.path.exists(images_dir):\n",
    "        image_paths = [os.path.join(images_dir, filename) for filename in os.listdir(images_dir)]\n",
    "    else:\n",
    "        print(\"Provided path is incorrect\")\n",
    "        image_paths = []\n",
    "\n",
    "    document_labels = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = Image.open(os.path.join(images_dir, path))\n",
    "        try:\n",
    "            inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "            label_mapping = {0: 'id', 1: 'idObcy', 2: 'inne', 3: 'paszport', 4: 'paszportObcy', 5: 'prawoJazdy', 6: 'prawoJazdyObce'}\n",
    "            predicted_class_name = label_mapping[predicted_label]\n",
    "\n",
    "            document_labels.append({predicted_class_name: path})\n",
    "        \n",
    "        except Exception as e:  \n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "    \n",
    "    return document_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_ocr import extract_text_from_images\n",
    "\n",
    "def nlp_model_function(images_dir):\n",
    "    document_labels = cnn_model_function(images_dir)\n",
    "    print(document_labels)\n",
    "    \n",
    "    values_for_unknown_label = [entry for entry in document_labels if 'inne' in entry]\n",
    "    print(values_for_unknown_label)\n",
    "\n",
    "    nlp_dictionary = []\n",
    "\n",
    "    if len(values_for_unknown_label) > 0:\n",
    "        for entry in values_for_unknown_label:\n",
    "            path = list(entry.values())[0] #filrs element of every entry which is a one key:value pair dictionary\n",
    "            print(path)\n",
    "            text_from_image = extract_text_from_images([path])\n",
    "            print(text_from_image)\n",
    "            predicted_class = predict_sentiment(text_from_image)\n",
    "            print(predicted_class)\n",
    "            nlp_dictionary.append({\n",
    "                predicted_class:path\n",
    "            })\n",
    "    \n",
    "        document_labels.append(nlp_dictionary)\n",
    "        return document_labels\n",
    "\n",
    "    else:\n",
    "        return document_labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function():\n",
    "    dane = nlp_model_function(images_dir=\"/content/zdjecia\")\n",
    "    print(dane)\n",
    "    return dane\n",
    "\n",
    "main_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
