{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Pytorch\n",
    "%pip install \"torch==2.2.2\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n",
    "\n",
    "# Install remaining libraries\n",
    "%pip install \"Pillow==9.5.0\" \"matplotlib==3.8.0\" \"numpy==1.24.3\" \"pandas==2.1.0\" \"tqdm==4.66.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from transformers import LlamaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_model_dir = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(NLP_model_dir)\n",
    "nlp_model = LlamaForSequenceClassification(NLP_model_dir, num_labels=4)\n",
    "nlp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"E:\\\\Projekty\\\\for_work\\\\docs-det-all-nations\\\\dit-baseDocument_Classification-ids-seria-21\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_dir)\n",
    "\n",
    "def cnn_model_function(images_dir):\n",
    "\n",
    "    if os.path.exists(images_dir):\n",
    "        image_paths = [os.path.join(images_dir, filename) for filename in os.listdir(images_dir)]\n",
    "    else:\n",
    "        print(\"Provided path is incorrect\")\n",
    "        image_paths = []\n",
    "\n",
    "    document_labels = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = Image.open(os.path.join(images_dir, path))  \n",
    "        try:\n",
    "            inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "            label_mapping = {0: 'id', 1: 'idObcy', 2: 'inne', 3: 'paszport', 4: 'paszportObcy', 5: 'prawoJazdy', 6: 'prawoJazdyObce'}\n",
    "            predicted_class_name = label_mapping[predicted_label]\n",
    "\n",
    "            document_labels.append({predicted_class_name: path})  \n",
    "        \n",
    "        except Exception as e:  \n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "    \n",
    "    return document_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Force CPU usage\n",
    "    device = torch.device(\"cpu\")\n",
    "    nlp_model.to(device)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = nlp_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return predicted_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_ocr import extract_text_from_images\n",
    "\n",
    "def nlp_model_function(CNN_model_dir, images_dir):\n",
    "    document_labels = cnn_model_function(CNN_model_dir, images_dir)\n",
    "    \n",
    "    values_for_unknown_label = [entry for entry in document_labels if 'inne' in entry]\n",
    "\n",
    "    nlp_dictionary = {}\n",
    "\n",
    "    if len(values_for_unknown_label) > 0:\n",
    "        for entry in values_for_unknown_label:\n",
    "            path = list(entry.values())[0] #filrs element of every entry which is a one key:value pair dictionary\n",
    "            text_from_image = extract_text_from_images(path) \n",
    "            predicted_class = predict_sentiment(text_from_image)\n",
    "            nlp_dictionary[path] = predicted_class\n",
    "    \n",
    "    return nlp_dictionary\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
